---
title: "Kolowium z SMLIN"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Przyjęty poziom istotności: 0.05\
Przyjęty poziom ufności: 0.95\

### Wczytanie bibliotek:

```{r}
library(datasets)  # iris, PlantGrowth, InsectSprays, airquality
library(car)       # Mroz, Salaries, vif, leveneTest, powerTransform
library(faraway)   # pima, wcgs, coagulation
library(agricolae) # sweetpotato, greenhouse, LSD.test
library(datarium)  # heartattack, jobsatisfaction, titanic.raw
library(caret)     # Sacramento, confusionMatrix
library(lmtest)    # bptest, dwtest, bgtest, resettest
library(MASS)      # stepAIC
library(pscl)      # pR2
library(ResourceSelection) # hoslem.test
library(dplyr)     # manipulacja danymi
```

## Zadanie 1.

Dane: `datasets::iris`\

Zbiór danych `datasets::iris` zawiera pomiary w centymetrach długości i szerokości działki kielicha (`sepal`) oraz długości i szerokości płatka (`petal`) 50 kwiatów trzech odmian gatunku irys. Wykonaj poniższe polecenia i odpowiedz na zadane pytania.\

Przygotowanie danych:

```{r}
dane1 <- data.frame(iris)
head(dane1)
```

### (A)
Zbuduj model wyjaśniający zmienność długości działki kielicha od szerokości działki kielicha i szerokości
płatka rozważanego gatunku kwiatów. 

```{r}
model1A <- lm(Sepal.Length ~ Sepal.Width + Petal.Width, data = dane1)
model1A
```

Zbudowano model liniowy wyjaśniający długość działki kielicha od szerokości działki kielicha i szerokości płatka, postaci: Sepal.Length = 3.46 + 0.4 * Sepal.Width + 0.97 * Petal.Width.

### (B)
Sprawdź, czy istnieje interakcja między zmiennymi objaśniającymi w modelu zbudowanym w punkcie (A).\

H0: Współczynnik przy interakcji (Sepal.Width:Petal.Width) jest równy 0.\
H1: Współczynnik przy interakcji jest różny od 0.

```{r}
model1B <- lm(Sepal.Length ~ Sepal.Width * Petal.Width, data = dane1)
summary(model1B)
```

P-wartość dla testu t wynosi 0.5, co jest większe niż przyjęty poziom istotności 0.05. W związku z tym nie mamy podstaw do odrzucenia hipotezy zerowej, zatem nie mamy istotnej statystcznie interakcji pomiędzy zmiennymi objaśniającymi.

### (C)
Wyznacz przedziały ufności dla wszystkich współczynników modelu (A). 

```{r}
p <- length(model1A$coefficients)
alpha <- (1-0.95)/p
print("Indywidualny poziom ufności:")
print(1 - alpha)
print("Przedziały ufności dla współczynników modelu (A):")
confint(model1A, level=(1 - alpha))
```

Z prawdopodobieństwem 0.98 wyznaczony przedział ufności (0.18, 0.62) pokrywa nieznaną wartość parametru strukturalnego przy zmiennej `Sepal.Width`. Przedział nie zawiera zera, zatem zmienna jest istotna.\
Z prawdopodobieństwem 0.98 wyznaczony przedział ufności (0.85, 1.1) pokrywa nieznaną wartość parametru strukturalnego przy zmiennej `Petal.Width`. Przedział nie zawiera zera, zatem zmienna jest istotna.

### (D)
Zmodyfikuj model otrzymany w punkcie (A) logarytmując zmienne objaśniające. Podaj interpretacje współczynników w otrzymanym modelu. 

```{r}
model1D <- lm(Sepal.Length ~ log(Sepal.Width) + log(Petal.Width), data = dane1)
model1D
model1D$coefficients/100
```

Zbudowano model liniowy wyjaśniający długość działki kielicha od logarytmu szerokości działki kielicha i logarytmu szerokości płatka, postaci: Sepal.Length = 3.95 + 1.83 * log(Sepal.Width) + 0.79 * log(Petal.Width).\
Wzrost szerokości działki kielicha (Sepal.Width) o 1% powoduje wzrost długości działki kielicha (Sepal.Length) o ok. 0.02 jednostek długości, przy założeniu stałości pozostałych zmiennych.\
Wzrost szerokości płatka (Petal.Width) o 1% powoduje wzrost długości działki kielicha (Sepal.Length) o ok. 0.01 jednostek długości, przy założeniu stałości pozostałych zmiennych.

### (E)
Zbadaj, czy w zbudowanym modelu w punkcie (A) błędy są homoskedastyczne. W przypadku odpowiedzi negatywnej sprawdź, czy zlogarytmowanie zmiennych objaśniających w punkcie (D) wymusiło homoskedastyczność błędów.\

Test Breuscha–Pagana:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model1A, studentize = FALSE)
```

Test Koenkera–Basseta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model1A, studentize = TRUE)
```

Test Goldfelda–Quandta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
gqtest(model1A)
```

Test White’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model1A, varformula= ~Sepal.Width + Petal.Width + I(Sepal.Width^2) + I(Petal.Width^2), data=dane1, studentize=FALSE)
```

Test Harrisona–McCabe’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
hmctest(model1A)
```

P-wartości dla wszystkich przeprowadzonych testów są mniejsze niż każdy sensownie przyjęty poziom istotności, więc odrzucamy hipotezę zerową, zatem założenie o homoskedastyczności błędów zostało naruszone. W tym wypadku zgodnie z poleceniem sprawdzimy czy zlogarytmowanie zmiennych objaśniających wymusiło homoskedastyczność błędów.\

Test Breuscha–Pagana:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model1D, studentize = FALSE)
```

Test Koenkera–Basseta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model1D, studentize = TRUE)
```

Test Goldfelda–Quandta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
gqtest(model1D)
```

Test White’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model1D, varformula= ~Sepal.Width + Petal.Width + I(Sepal.Width^2) + I(Petal.Width^2), data=dane1, studentize=FALSE)
```

Test Harrisona–McCabe’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
hmctest(model1D)
```

Ponownie p-wartości dla wszystkich przeprowadzonych testów są mniejsze niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem założenie o homoskedastyczności błędów zostało naruszone również w modelu o zlogarytmowanych zmiennych objaśniających.

### (F)
Przeprowadź analizę kontrastów Helmerta, aby sprawdzić, czy rozważane odmiany kwiatów irys różnią się długością działki kielicha.

Model:\
$weight = \beta_0 + \beta_1*gversicolor + \beta_2*gvirginica$\

Kontrast 1:\
$0 > \beta_1 = \mu_{versicolor} - \mu_{setosa}$\

H0: $\beta_1 = 0$\
H0: $\mu_{versicolor} = \mu_{setosa}$\

Kontrast 2:\
$0 < \beta_2 = \mu_{virginica} - \mu_{setosa}$\

H0: $\beta_2 = 0$\
H0: $\mu_{virginica} = \mu_{setosa}$\

```{r}
contrasts(dane1$Species) <- contr.helmert
contrasts(dane1$Species)
S <- cbind(1, contrasts(dane1$Species))
S
S_2 <- solve(S)
print("Macierz wpółczynników kontrastów:")
fractions(S_2)
```

Zdefiniowano kontrasty:\
$\beta_0 \quad to \quad L_1 = \frac{1}{3} (\mu_{setosa} + \mu_{versicolor} + \mu_{virginica})$\
$\beta_1 \quad to \quad L_2 = -\frac{1}{2} \mu_{setosa} + \frac{1}{2} \mu_{versicolor}$\
$\beta_2 \quad to \quad L_3 = -\frac{1}{6} (\mu_{setosa} - \mu_{versicolor}) + \frac{1}{3} \mu_{virginica}$\

H0: $L_k = 0$\
H1: $L_k \neq 0$\

```{r}
model1_contr <- lm(Sepal.Length ~ Species, data = dane1, contrasts = contrasts(dane1$Species))
summary(model1_contr)
```

Species1, czyli kontrast $L_2$ jest istotny statystycznie, ponieważ p-wartość dla tego kontrastu jest mniejsza niż przyjęty poziom istotności 0.05. Oznacza to, że średnia długość działki kielicha dla gatunku versicolor istotnie różni się od średniej długości działki kielicha dla gatunku setosa, a uwzględniając dodatni współczynnik (0.47) możemy stwierdzić, że jest istotnie większa.\

Species2, czyli kontrast $L_3$ jest istotny statystycznie, ponieważ p-wartość dla tego kontrastu jest mniejsza niż przyjęty poziom istotności 0.05. Oznacza to, że średnia długość działki kielicha dla gatunku virginica różni się istotnie od średniej długości działki kielicha dla pozostałych gatunków, a uwzględniając dodatni współczynnik (0.37) możemy stwiedzić, że jest istotnie większa.

## Zadanie 2.
W zbiorze `Mroz` biblioteki `car` znajdują się dane dotyczące zatrudnienia zamężnych kobiet. Zbiór zawiera 8 zmiennych:\

  - lfp – zatrudnienie, czynnik z poziomami no (kobieta nie jest zatrudniona) i yes (kobieta jest zatrudniona),\
  - k5 – liczba dzieci do piątego roku życia,\
  - k618 – liczba dzieci w wieku od 6 do 18 lat,\
  - age – wiek kobiety w latach,\
  - wc – uczęszczanie na studia, czynnik z poziomami no (kobieta nie uczęszcza na studia) i yes (kobieta uczęszcza na studia) ,\
  - hc – uczęszczanie męża na studia, czynnik z poziomami no (mąż nie uczęszcza na studia) i yes (mąż uczęszcza na studia),\
  - lwg – logarytm oczekiwanej stawki wynagrodzenia,\
  - inc – dochód rodziny bez dochodu kobiety.\

Przygotowanie danych:

```{r}
dane2 <- data.frame(Mroz)
head(dane2)
```

### (A)
Stosując selekcję w przód zbuduj model za pomocą, którego można określić szanse na to, że losowo wybrana kobieta jest zatrudniona.

```{r}
model2_empty <- glm(lfp ~ 1, data=dane2, family = "binomial")
model2_full <- glm(lfp ~ ., data=dane2, family = "binomial")
model2_forward <- step(model2_empty, scope = list(lower = model2_empty, upper = model2_full), direction = "forward", trace = 0)
model2_forward
summary(model2_full)
```

Metoda selekcji w przód (funkcja step), opierając się na kryterium AIC, dobrała optymalny zestaw zmiennych najlepiej wyjaśniających szansę kobiety na zatrudnienie wybierając następujący model: : lfp = 2.9 - 1.43 * k5 - 0.06 * age + 0.62 * lwg - 0.03 * inc + 0.87 * wc. Zatem zmienne `k618` i `hc` (dzieci w wieku 6-18 lat i uczęszczanie męża na studia) nie miały istotnego wpływu na zmienną binarną `lfp` (czy kobieta jest zatrudniona). Co możemy potwierdzić patrząc na wyniki testu t dla modelu pełnego, gdzie p-wartość tego testu dla zmiennych `k618` i `hc` jest powyżej przyjętego poziomu istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, mówiącej, że wpółczynniki te są równe 0.

### (B)
Na podstawie zbudowanego modelu w punkcie (A) odpowiedz na pytanie: jaki wpływ na zatrudnienie kobiety ma to, że uczęszcza na studia, a jaki wpływ na zatrudnienie kobiety ma jej wiek?

```{r}
exp(coef(model2_forward))
```

Jeśli kobieta uczęszcza na studia, to jej szansa na zatrudnienie zwiększa się o 139%, przy założeniu stałości pozostałych zmiennych.\
Jeśli wiek kobiety wzrośnie o 1 rok, to jej szansa na zatrudnienie zmniejszy się o 6%, przy założeniu stałości pozostałych zmiennych.

### (C)
Przyjmując próg klasyfikacyjny 0.5 stwórz zmienną zero-jedynkową `pred`, za pomocą której można określić, czy na podstawie zbudowanego modelu zamężna kobieta jest zatrudniona, a następnie oblicz miary oceny jakości prognoz i na ich podstawie dokonaj oceny zbudowanego modelu.

```{r}
dane2$pred <- ifelse(predict(model2_forward, type = "response") >= 0.5, "yes", "no")
head(dane2)
```

```{r}
confusionMatrix(as.factor(dane2$pred), as.factor(dane2$lfp), positive = "yes")
```

  1. Na podstawie accuracy równego 0.681 wnioskujemy że model przewidział ok.68% poprawnych wartości.\
  2. Precision (pos pred value) wynosi 0.695 co oznacza że ze wszystkich przewidzianych pozytywnych przypadków ok.70% faktycznie było pozytywnych. Mówi się w takim przypadku, że model rzadko generuje fałszywe alarmy.\
  3. Czułość (sensitivity/recall) wynosi 0.783 co oznacza, że ok. 78% zatrudnionych kobiet model wskazał poprawnie.\
  4. Swoistość (specificity) wynosi 0.548 co oznacza, że ok. 55% nie zatrudnionych kobiet model wskazal poprawnie.\

Za pomocą zbudowanego modelu przyjmująć próg klasyfikacyjny 0.5 lepiej można przewidzieć to, że kobieta jest zatrudniona, niż to, że nie jest. Model ma wysoką precyzję i jest bardziej nastawiony na wykrywanie pozytywnych przypadków.

## Zadanie 3.
Oceniono typ osobowości 3154 zdrowych mężczyzn w wieku 39-59 lat zamieszkałych w San Francisco. Obserwacje zapisano w zbiorze `faraway::wcgs`. Na podstawie tych obserwacji chcemy odpowiedzieć na pytanie, jaki jest wpływ masy ciała (`weight`), stężenia cholesterolu we krwi (`chol`) i typu osobowości (`dibep`) na to, czy u danego mężczyzny stwierdzono chorobę wieńcową (`chd`). W tym celu zapoznaj się z informacjami zawartymi w pomocy *RStudio*, a następnie zbuduj odpowiedni model włączając do niego **tylko wymienione wyżej zmienne**.\

Przygotowanie danych i budowa modelu:

```{r}
dane3 <- na.omit(data.frame(wcgs))
head(dane3)
```

```{r}
model3 <- glm(chd ~ weight + chol + dibep, data = dane3, family = "binomial")
model3
```

Zbudowano model logistyczny wyjaśniający prawdopodobieństwo stwierdzenia choroby wieńcowej (chd) na podstawie masy ciała (weight), stężenia cholesterolu we krwi (chol) i typu osobowości (dibep), postaci: chd = -6.65 + 0.01 * weight + 0.01 * chol - 0.81 * dibep.

### (A)
Podaj interpretacje współczynników zbudowanego modelu.

```{r}
exp(coef(model3))
```

 1. Wzrost masy ciała (weight) o 1 funt powoduje wzrost szansy na stwierdzenie choroby wieńcowej (chd) o około 1% przy założeniu stałości pozostałych zmiennych.\
 2. Wzrost stężenia cholesterolu we krwi (chol) o 1 jednostkę (mm%) powoduje wzrost szansy na stwierdzenie choroby wieńcowej (chd) o około 1% przy założeniu stałości pozostałych zmiennych.\
 3. Zmiana typu osobowości z typu A (agresywny) na typ B (pasywny) powoduje spadek szansy na stwierdzenie choroby wieńcowej (chd) o około 55% przy założeniu stałości pozostałych zmiennych.

### (B)
Przyjmując próg klasyfikacyjny 0.6 stwórz zmienną zero-jedynkową pred, za pomocą której można określić, czy na podstawie zbudowanego modelu stwierdzono chorobę wieńcową, a następnie oblicz miary oceny jakości prognoz i na ich podstawie dokonaj oceny zbudowanego modelu. 

```{r}
dane3$pred <- ifelse(predict(model3, type = "response") >= 0.6, "yes", "no")
head(dane3)
```

```{r}
confusionMatrix(as.factor(dane3$pred), as.factor(dane3$chd), positive = "yes")
```

  1. Na podstawie accuracy równego 0.92 wnioskujemy że model przewidział ok.92% poprawnych wartości.\
  2. Precision (pos pred value) wynosi 1 co oznacza że ze wszystkich przewidzianych pozytywnych przypadków 100% faktycznie było pozytywnych. Mówi się w takim przypadku, że model nie generuje fałszywych alarmów.\
  3. Czułość (sensitivity/recall) wynosi 0.004 co oznacza, że ok. 0,4% osób, u których stwierdzono chorobę wieńcową (chd) model poprawnie wskazał.\ 
  4. Swoistość (specificity) wynosi 1 co oznacza, że 100% osób, u których nie stwierdzono choroby wieńcowej (chd) model wskazał poprawnie.\

Za pomocą zbudowanego modelu przyjmująć próg klasyfikacyjny 0.6 lepiej można przewidzieć to, że u mężczyzny nie stwierdzono choroby wieńcowej, niż to, że ją stwierdzono. Model ma nie naturalnie wysoką precyzję. Model ma dużą tendencję do ovefittingu i nie wykrywa poprawnie czy u danej osoby stwierdzono chorobę wieńcową.

## Zadanie 4.
Na podstawie zbioru `faraway::wcgs` zbuduj model liniowy zależności ciśnienia skurczowego (`sdp`), od wieku (`age`), poziomu cholesterolu (`chol`), masy ciała (`weight`) oraz liczby wypalanych papierosów (`cigs`).\

Przygotowanie danych i budowa modelu:

```{r}
dane4 <- na.omit(data.frame(wcgs))
head(dane4)
```

```{r}
model4 <- lm(sdp ~ age + chol + weight + cigs, data = dane4)
model4
```

Zbudowano model liniowy wyjaśniający ciśnienie skurczowe (sdp) od wieku (age), poziomu cholesterolu (chol), masy ciała (weight) oraz liczby wypalanych papierosów (cigs), postaci: sdp = 67.19 + 0.46 * age + 0.04 * chol + 0.19 * weight + 0.04 * cigs.

### (A)
Sprawdź, czy w zbudowanym modelu zostało naruszone założenie o jednorodności wariancji składnika losowego.

Test Breuscha–Pagana:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model4, studentize = FALSE)
```

Test Koenkera–Basseta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model4, studentize = TRUE)
```

Test Goldfelda–Quandta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
gqtest(model4)
```

Test White’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model4, varformula= ~age + chol + weight + cigs + I(age^2) + I(chol^2) + I(weight^2) + I(cigs^2), data=dane4, studentize=FALSE)
```

Test Harrisona–McCabe’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
hmctest(model4)
```

P-wartości dla wszystkich przeprowadzonych testów za wyjątkiem testu Goldfelda–Quandta i Harrisona–McCabe’a są mniejsze niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem założenie o homoskedastyczności błędów zostało naruszone.\
W przypadku testu Goldfelda–Quandta i Harrisona–McCabe’a p-wartość jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem nie mamy podstaw do stwierdzenia naruszenia założenia o homoskedastyczności błędów.\
Ponieważ większość testów wskazuje na naruszenie założenia o homoskedastyczności błędów, możemy stwierdzić, że w zbudowanym modelu zostało naruszone założenie o jednorodności wariancji składnika losowego.

### (B)
Czy zlogarytmowanie zmiennych objaśniających wymusi homoskedastyczność błędów zbudowanego modelu. Zauważ, że zmiennej `cigs` nie możemy logarytmować, albowiem może przyjmować wartości równe zero.

```{r}
model4_log <- lm(sdp ~ log(age) + log(chol) + log(weight) + cigs, data = dane4)
model4_log
```

Zbudowano model liniowy wyjaśniający ciśnienie skurczowe (sdp) od logarytmu wieku (age), logarytmu poziomu cholesterolu (chol), logarytmu masy ciała (weight) oraz liczby wypalanych papierosów (cigs), postaci: sdp = -157.24 + 21.93 * log(age) + 7.84 * log(chol) + 31.01 * log(weight) + 0.04 * cigs.\

Zbadanie czy zlogarytmowanie zmiennych objaśniających wymusiło homoskedastyczność błędów:

Test Breuscha–Pagana:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model4_log, studentize = FALSE)
```

Test Koenkera–Basseta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model4_log, studentize = TRUE)
```

Test Goldfelda–Quandta:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
gqtest(model4_log)
```

Test White’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
bptest(model4_log, varformula= ~age + chol + weight + cigs + I(age^2) + I(chol^2) + I(weight^2) + I(cigs^2), data=dane4, studentize=FALSE)
```

Test Harrisona–McCabe’a:\

H0: Wariancja składnika losowego jest stała\
H1: Wariancja składnika losowego nie jest stała (heteroskedastyczność)

```{r}
hmctest(model4_log)
```

Ponownie jak w przypadku pierwotnej wersji modelu dla wszystkich przeprowadzonych testów za wyjątkiem testu Goldfelda–Quandta i Harrisona–McCabe’a p-wartości są mniejsze niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem założenie o homoskedastyczności błędów zostało naruszone.

### (C)
Podaj interpretacje współczynników stojących przy zmiennej cigs i weight w modelu zbudowanym w punkcie (B).

```{r}
coef(model4_log)
```

 1. Wzrost liczby wypalanych papierosów (cigs) o 1 powoduje wzrost ciśnienia skurczowego (sdp) o ok. 0.04 mm Hg przy założeniu stałości pozostałych zmiennych.\
 2. Wzrost masy ciała (weight) o 1% powoduje wzrost ciśnienia skurczowego (sdp) o ok. 0.31 mm Hg przy założeniu stałości pozostałych zmiennych.\

## Zadanie 5.
Firma farmaceutyczna przetestowała trzy różne sposoby leczenia osób wysokim poziomie cholesterolu. W eksperymencie wzięło udział 72 uczestników. Celem badania było sprawdzenie działania nowej klasy leków (`drug`) na obniżenie poziomu cholesterolu (`cholesterol`). Zebrane dane znajdują się w zbiorze `datarium::heartattack`.

Przygotowanie danych:

```{r}
dane5 <- data.frame(heartattack)
head(dane5)
```

### (A)
Za pomocą odpowiedniego testu zweryfikuj hipotezę, że średni poziom cholesterolu różni się w zależności od podanego leku.

H0: Średni poziom cholesterolu jest taki sam dla wszystkich trzech leków.\
H1: Średni poziom cholesterolu różni się w zależności od podanego leku.\

Przed sprawdzeniem hipotezy należy sprawdzić, czy zostały spełnione założenia testu ANOVA, czyli równoliczniść, normalność rozkładu reszt oraz jednorodność wariancji.\

Sprawdzenie założenia o rónoliczności:

```{r}
table(dane5$drug)
```

Założenie o równoliczności jest spełnione, ponieważ w każdej grupie jest po 24 obserwacje.\

Test Shapiro–Wilka dla normalności rozkładu reszt:\

H0: Średni poziom cholesterolu dla leku A ma rozkład normalny.\
H1: Średni poziom cholesterolu dla leku A nie ma rozkładu normalnego.\
H0: Średni poziom cholesterolu dla leku B ma rozkład normalny.\
H1: Średni poziom cholesterolu dla leku B nie ma rozkładu normalnego.\
H0: Średni poziom cholesterolu dla leku C ma rozkład normalny.\
H1: Średni poziom cholesterolu dla leku V nie ma rozkładu normalnego.

```{r}
tapply(dane5$cholesterol, dane5$drug, shapiro.test)
```

Dla każdej grupy na każdym sensownym poziomie isotności nie mamy podstaw do odrzucenia hipotezy zerowej, zatem dane w poszczególnych grupach pochodzą z populacji o rozkładzie normalnym.\

Test Levene’a dla jednorodności wariancji:\

H0: Wariancja poziomu cholesterolu jest taka sama dla wszystkich trzech leków.\
H1: Wariancja poziomu cholesterolu różni się w zależności od podanego leku.

```{r}
leveneTest(cholesterol ~ drug, data = dane5)
```

P-wartość dla testu Levene’a jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem możemy przyjąć, że wariancja poziomu cholesterolu jest taka sama dla wszystkich trzech leków.\

Jako, wszystkie założenia zostały spełnione, możemy przeprowadzić test ANOVA:

H0: Średni poziom cholesterolu jest taki sam dla wszystkich trzech leków.\
H1: Średni poziom cholesterolu różni się w zależności od podanego leku.

```{r}
model5A <- aov(cholesterol ~ drug, data = dane5)
summary(model5A)
```

P-wartość dla testu ANOVA jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem średni poziom cholesterolu jest taki sam dla wszystkich trzech leków.

### (B)
Przeprowadź analizę kontrastów sum aby sprawdzić, czy średni poziom cholesterolu różni się w zależności od podanego leku.\

Model:\
$weight = \beta_0 + \beta_1*gB + \beta_2*gC$\

Kontrast 1:\
$0 > \beta_1 = \mu_{B} - \mu_{A}$\

H0: $\beta_1 = 0$\
H0: $\mu_{B} = \mu_{A}$\

Kontrast 2:\
$0 < \beta_2 = \mu_{C} - \mu_{A}$\

H0: $\beta_2 = 0$\
H0: $\mu_{C} = \mu_{A}$\

```{r}
contrasts(dane5$drug) <- contr.sum
contrasts(dane5$drug)
S <- cbind(1, contrasts(dane5$drug))
S
S_2 <- solve(S)
library(MASS)
print("Macierz współczynników kontrastów:")
fractions(S_2)
```

Zdefiniowano kontrasty:\
$\beta_0 \quad to \quad L_1 = \frac{1}{3} (\mu_{A} + \mu_{B} + \mu_{C})$\
$\beta_1 \quad to \quad L_2 = \frac{2}{3} \mu_{A} - \frac{1}{3} (\mu_{B} + \mu_{C})$\
$\beta_2 \quad to \quad L_3 = -\frac{1}{3} \mu_{A} + \frac{2}{3} \mu_{B} -\frac{1}{3} \mu_{C}$\

H0: $L_k = 0$\
H1: $L_k \neq 0$\

```{r}
model5_contr <- lm(cholesterol ~ drug, data = dane5, contrasts = contrasts(dane5$drug))
summary(model5_contr)
```

Dla kontrastu $L_2$ p-wartość jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni poziom cholesterolu dla leku B istotnie różni się od średniego poziomu cholesterolu dla leku A. Biorąc pod uwagę dodatni wpółczynnik (0.19) możemy stwierdzić, że średni poziom cholesterolu dla leku B jest większy niż dla leku A.\
Dla kontrastu $L_3$ p-wartość jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem średni poziom cholesterolu dla leku C nie różni się istotnie od średniego poziomu cholesterolu dla leku A i B.\

## Zadanie 6.
Zbiór danych pima biblioteki `faraway` zawiera wyniki badania przeprowadzonego na 768 dorosłych Indiankach Pima mieszkających w pobliżu Phoenix przez Narodowy Instytut Cukrzycy oraz Chorób Trawiennych i Nerek. Zbiór ten zawiera następujące zmienne:\

  - pregnant – liczba przebytych ciąż,\
  - glucose – stężenie glukozy w osoczu po 2 godzinach w doustnym teście tolerancji glukozy,\
  - diastolic – ciśnienie rozkurczowe krwi (mm Hg),\
  - triceps – grubość fałdu skórnego tricepsa (mm), antropometryczny wskaźnik oceny zasobów tkanki tłuszczowej,\
  - insulin – ilość insuliny w surowicy (mu U/ml),\
  - bmi – wskaźnik masy ciała (waga w kg/(wzrost w metrach do kwadratu)),\
  - diabetes – wskaźnik wystąpienia cukrzycy określający ryzyko genetyczne zachorowania na cukrzycę poprzez ocenę historii rodzinnej,\
  - age – wiek w latach,\
  - test – wynik testu sprawdzającego, czy u pacjentki występują objawy cukrzycy (0 w przypadku wyniku negatywnego, 1 w przypadku wyniku pozytywnego).\

Przygotowanie danych:

```{r}
dane6 <- data.frame(pima)
head(dane6)
```

### (A)
Na podstawie zbioru pima zbuduj model liniowy za pomocą którego możemy wyjaśnić wpływ stężenia glukozy we krwi (`glucose`) oraz wieku (`age`) na grubość fałdu skórnego tricepsa (`triceps`). Sprawdź, czy istnieje interakcja między zmiennymi objaśniającymi w zbudowanym modelu liniowym.\

H0: Współczynnik przy interakcji współczynników (glucose:age) jest równy 0.\
H1: Współczynnik przy interakcji jest różny od 0.

```{r}
model6A <- lm(triceps ~ glucose + age, data = dane6)
model6A
model6A_int <- lm(triceps ~ glucose * age, data = dane6)
summary(model6A_int)
```

Zbudowano model liniowy wyjaśniający grubość fałdu skórnego tricepsa (triceps) od stężenia glukozy we krwi (glucose) oraz wieku (age), postaci: triceps = 21.13 + 0.05 * glucose - 0.19 * age.\
P-wartość dla testu t wynosi 0.68, co jest większe niż przyjęty poziom istotności 0.05. W związku z tym nie mamy podstaw do odrzucenia hipotezy zerowej, zatem nie mamy istotnej statystcznie interakcji pomiędzy zmiennymi glucose i age.

### (B)
Zmodyfikuj zbudowany model liniowy w punkcie (A) logarytmując zmienną objaśnianą `age`. Podaj interpretacje współczynników w otrzymanym modelu.

```{r}
model6B <- lm(triceps ~ glucose + log(age), data = dane6)
model6B
```

Zbudowano model liniowy wyjaśniający grubość fałdu skórnego tricepsa (triceps) od stężenia glukozy we krwi (glucose) oraz logarytmu wieku (log(age)), postaci: triceps = 36.97 + 0.05 * glucose - 6.38 * log(age).\

 1. Wzrost stężenia glukozy we krwi o 1 jednostkę powoduje wzrost grubości fałdu skórnego tricepsa o około 0.05 mm przy założeniu stałości pozostałych zmiennych.\
 2. Wzrost logarytmu wieku o 1% powoduje spadek grubości fałdu skórnego tricepsa o około 0.06 mm przy założeniu stałości pozostałych zmiennych.

### (C)
Zbadaj, czy w zbudowanym modelu liniowym w punkcie (A) zostało naruszone założenie braku autokorelacji błędów. Użyj wszystkich poznanych testów na wykładzie.

H0: Autokorelacja reszt I rzędu nie występuje\
H1: Autokorelacja reszt I rzędu występuje\

Test Durbin–Watsona:\

```{r}
dwtest(model6A, alternative = "two.sided")
```

P-wartość dla testu Durbin–Watsona jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem w modelu nie występuje autokorelacja reszt I rzędu.\

W celu sprawdzenia autokorelacji reszt wyższych rzędów należy przeprowadzić test Breuscha–Godfreya:\

H0: Brak autokorelacji do rzędu 5\
H1: Istnieje autokorelacja do rzędu 5\

```{r}
bgtest(model6A, order = 5)
```

P-wartość testu Breuscha-Godfreya jest większa niż przyjęty poziom istotności, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem w modelu nie występuje autokorelacja reszt do rzędu 5. Sprawdzenie autokorelacji dla wyższych błędów nie jest konieczne. Założenie o braku autokorelacji błędów w tym modelu jest spełnione.

### (D)
Jaką grubość fałdu tricepsa możemy przewidzieć na podstawie modelu liniowego zbudowanego w punkcie (A) w przypadku 50-letniej Indianki, u której stężenie glukozy we krwi wynosi 100 mg/dL.

```{r}
new_data <- data.frame(glucose = 100, age = 50)
predicted_triceps <- predict(model6A, newdata = new_data)
predicted_triceps
```

Na podstawie zbudowanego modelu liniowego możemy przewidzieć, że grubość fałdu tricepsa dla 50-letniej Indianki, u której stężenie glukozy we krwi wynosi 100 mg/dL, wynosi około 16.40 mm.

### (E)
Na podstawie zbioru pima zbuduj model, za pomocą którego możemy wyjaśnić szanse na to, że u losowo wybranej Indianki Pima występują objawy cukrzycy. Do modelu włącz wszystkie zmienne. Na podstawie zbudowanego modelu określ jaki jest wpływ wskaźnika wystąpienia cukrzycy (`diabetes`) oraz ciśnienia rozkurczowego (`diastolic`) na to czy dana Indianka Pima jest chora na cukrzycę.

```{r}
model6E <- glm(test ~ ., data = dane6, family = "binomial")
model6E
exp(coef(model6E))
```

Zbudowano model logistyczny wyjaśniający prawdopodobieństwo wystąpienia objawów cukrzycy (test) na podstawie wszystkich zmiennych, postaci: test = -8.4 + 0.12 * pregnant + 0.04 * glucose - 0.01 * diastolic + 0.001 * triceps - 0.001 * insulin + 0.09 * bmi + 0.95 * diabetes + 0.01 * age\

 1. Wzrost wskaźnika wystąpienia cukrzycy o 1 powoduje wzrost szansy na to, że u badanej Indianki Pima występują objawy cukrzycy o ok. 157% przy założeniu stałości pozostałych zmiennych.\
 2. Wzrost ciśnienia rozkurczowego o 1 mm Hg powoduje spadek szansy na to, że u badanej Indianki Pima występują objawy cukrzycy o około 1% przy założeniu stałości pozostałych zmiennych.\

### (F)
Przyjmując próg klasyfikacyjny 0.7 stwórz zmienną zero-jedynkową `pred`, za pomocą której można określić, czy u badanej Indianki Pima występują objawy cukrzycy, a następnie oblicz miary oceny jakości prognoz i na ich podstawie dokonaj oceny zbudowanego modelu. 

```{r}
dane6$pred <- ifelse(predict(model6E, type = "response") >= 0.7, 1, 0)
head(dane6)
```

```{r}
confusionMatrix(as.factor(dane6$pred), as.factor(dane6$test), positive = "1")
```

  1. Na podstawie accuracy równego 0.75 wnioskujemy że model przewidział ok.75% poprawnych wartości.\
  2. Precision (pos pred value) wynosi 0.82 co oznacza że ze wszystkich przewidzianych pozytywnych przypadków ok. 82% faktycznie było pozytywnych. Mówi się w takim przypadku, że model rzadko generuje fałszywe alarmy.\
  3. Czułość (sensitivity/recall) wynosi 0.37 oznacza, że ok. 37% osób, u których występują objawy cukrzycy model poprawnie wskazał.\ 
  4. Swoistość (specificity) wynosi 0.97 oznacza, że ok. 97% osób, u których nie występują objawy cukrzycy model wskazał poprawnie.\

Za pomocą zbudowanego modelu przyjmująć próg klasyfikacyjny 0.7 lepiej można przewidzieć to, że u badanej Indianki Pima nie występują objawy cukrzycy niż to, że występują. Model ma wysoką precyzję i jest bardziej nastawiony na wykrywanie negatywnych przypadków.

## Zadanie 7.
W zbiorze `faraway::coagulation` zostały zapisane czasy krzepnięcia krwi pobranej od 24 zwierząt oraz sposób ich żywienia.\

Przygotowanie danych:

```{r}
dane7 <- data.frame(coagulation)
head(dane7)
```

### (A)
Za pomocą odpowiedniego testu zweryfikuj hipotezę, że średni czas krzepnięcia krwi różni się w zależności sposobu żywienia.

H0: Średni czas krzepnięcia krwi jest taki sam dla wszystkich sposobów żywienia.\
H1: Średni czas krzepnięcia krwi różni się od sposobu żywienia.\

Przed sprawdzeniem hipotezy należy sprawdzić, czy zostały spełnione założenia testu ANOVA, czyli równoliczność grup, normalność rozkładu reszt oraz jednorodność wariancji.\

Sprawdzenie założenia o równoliczności:

```{r}
table(dane7$diet)
```

Założenie o równoliczności nie jest spełnione, przy czym różnice są niewielkie, na co test ANOVA jest odporny. Należy sprawdzić pozostałe założenia.\

Test Shapiro–Wilka dla normalności rozkładu reszt:\

H0: Średni czas krzepnięcia krwi dla sposobu A ma rozkład normalny.\
H1: Średni czas krzepnięcia krwi dla sposobu A nie ma rozkładu normalnego.\
H0: Średni czas krzepnięcia krwi dla sposobu B ma rozkład normalny.\
H1: Średni czas krzepnięcia krwi dla sposobu B nie ma rozkładu normalnego.\
H0: Średni czas krzepnięcia krwi dla sposobu C ma rozkład normalny.\
H1: Średni czas krzepnięcia krwi dla sposobu C nie ma rozkładu normalnego.\
H0: Średni czas krzepnięcia krwi dla sposobu D ma rozkład normalny.\
H1: Średni czas krzepnięcia krwi dla sposobu D nie ma rozkładu normalnego.

```{r}
tapply(dane7$coag, dane7$diet, shapiro.test)
```

Dla każdej grupy na każdym sensownym poziomie isotności nie mamy podstaw do odrzucenia hipotezy zerowej, zatem dane w poszczególnych grupach pochodzą z populacji o rozkładzie normalnym.\

Test Levene’a dla jednorodności wariancji:\

H0: Wariancja czasu krzepnięcia krwi jest taka sama dla wszystkich sposobów żywienia.\
H1: Wariancja czasu krzepnięcia krwi różni się w zależności od sposobu żywienia.

```{r}
leveneTest(coag ~ diet, data = dane7)
```

P-wartość dla testu Levene’a jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem możemy przyjąć, że wariancja czasu krzepnięcia krwi jest taka sama dla wszystkich czterech sposobów żywienia.\

Jako, wszystkie założenia zostały spełnione, możemy przeprowadzić test ANOVA:

H0: Średni czas krzepnięcia krwi jest taki sam dla wszystkich sposobów żywienia.\
H1: Średni czas krzepnięcia krwi różni się od sposobu żywienia.\

```{r}
model7A <- aov(coag ~ diet, data = dane7)
summary(model7A)
```

P-wartość dla testu ANOVA jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni czas krzepnięcia krwi różni się w zależności od sposobu żywienia.

### (B)
Przeprowadź analizę kontrastów Helmerta aby sprawdzić, czy średni czas krzepnięcia krwi różni się w zależności od sposobu żywienia.\

Model:\
$weight = \beta_0 + \beta_1*gB + \beta_2*gC + \beta_3*gD$\

Kontrast 1:\
$0 > \beta_1 = \mu_{B} - \mu_{A}$\

H0: $\beta_1 = 0$\
H0: $\mu_{B} = \mu_{A}$\

Kontrast 2:\
$0 < \beta_2 = \mu_{C} - \mu_{A}$\

H0: $\beta_2 = 0$\
H0: $\mu_{C} = \mu_{A}$\

Kontrast 3:\
$0 < \beta_3 = \mu_{D} - \mu_{A}$\

H0: $\beta_3 = 0$\
H0: $\mu_{D} = \mu_{A}$\

```{r}
contrasts(dane7$diet) <- contr.helmert
contrasts(dane7$diet)
S <- cbind(1, contrasts(dane7$diet))
S
S_2 <- solve(S)
library(MASS)
print("Macierz współczynników kontrastów:")
fractions(S_2)
```

Zdefiniowano kontrasty:\
$\beta_0 \quad to \quad L_1 = \frac{1}{4} (\mu_{A} + \mu_{B} + \mu_{C} + \mu_{D})$\
$\beta_1 \quad to \quad L_2 = -\frac{1}{2} \mu_{A} + \frac{1}{2} \mu_{B}$\
$\beta_2 \quad to \quad L_3 = -\frac{1}{6} (\mu_{A} + \mu_{B}) + \frac{1}{3} \mu_{C}$\
$\beta_3 \quad to \quad L_4 = -\frac{1}{12} (\mu_{A} + \mu_{B} + \mu_{C}) + \frac{1}{4} \mu_{D}$\

H0: $L_k = 0$\
H1: $L_k \neq 0$\

```{r}
model7_contr <- lm(coag ~ diet, data = dane7, contrasts = contrasts(dane7$diet))
summary(model7_contr)
```

Dla kontrastu $L_2$ p-wartość jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni czas krzepnięcia krwi dla diety B istotnie różni się od średniego czasu krzepnięcia krwi dla diety A. Biorąc pod uwagę dodatni wpółczynnik (2.5) możemy stwierdzić, że średni czasu krzepnięcia krwi dla diety B jest większy niż dla diety A.\
Dla kontrastu $L_3$ p-wartość jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni czas krzepnięcia krwi dla diety C istotnie różni się od średniego czasu krzepnięcia krwi dla diety A i B. Biorąc pod uwagę dodatni wpółczynnik (1.5) możemy stwierdzić, że średni czasu krzepnięcia krwi dla diety C jest większy niż dla diety A i B.\
Dla kontrastu $L_4$ p-wartość jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni czas krzepnięcia krwi dla diety D istotnie różni się od średniego czasu krzepnięcia krwi dla diety A, B i C. Biorąc pod uwagę ujemny wpółczynnik (-1) możemy stwierdzić, że średni czasu krzepnięcia krwi dla diety D jest mniejszy niż dla diety A, B i C.

## Zadanie 8.
W zbiorze `agricolae::sweetpotato` znajdują się dane pochodzące z eksperymentu przeprowadzonego na słodkich ziemniakach (Costanero) w departamencie Tacna, południowe Peru. Badano wpływ dwóch wirusów Spcsv i Spfmv na plon roślin. Na każdej spośród 12 działek zasiano 50 roślin, przy czym każdy wariant powtarzano 3 razy. Po upływie pewnego czasu zmierzono masę plonów w kilogramach (`yield`). Zmienna `virus` przyjmuje wartości:\

  - CC – zakażenie wirusem Spcsv powodującym żółknięcie i niższy wzrost,\
  - FF – zakażenie wirusem Spfmv powodującym plamy na liściach,\
  - FC – zakażenie obu wirusami,\
  - OO – brak zakażenia.\

Na podstawie zbioru `sweetpotato` chcemy zweryfikować, czy średni plon słodkich ziemniaków różni się w zależności od sposobu zakażenia wirusami *Spcsv* i *Spfmv*. W tym celu wykonaj poniższe polecenia.\
Zweryfikuj postawioną hipotezę za pomocą:\

Przygotowanie danych:

```{r}
data(sweetpotato)
dane8 <- data.frame(sweetpotato)
head(dane8)
```

### (A)
odpowiedniego testu.

H0: Średni plon ziemniaków jest taki sam dla wszystkich sposobów zakażenia.\
H1: Średni plon ziemniaków różni się od sposobu zakażenia.\

Przed sprawdzeniem hipotezy należy sprawdzić, czy zostały spełnione założenia testu ANOVA, czyli równoliczność grup, normalność rozkładu reszt oraz jednorodność wariancji.\

Sprawdzenie założenia o równoliczności:

```{r}
table(dane8$virus)
```

Założenie o równoliczności jest spełnione, wszystkie grupy liczą po 3 obserwacje\

Test Shapiro–Wilka dla normalności rozkładu reszt:\

H0: Średni plon ziemniaków dla sposobu cc ma rozkład normalny.\
H1: Średni plon ziemniaków dla sposobu cc nie ma rozkładu normalnego.\
H0: Średni plon ziemniaków dla sposobu fc ma rozkład normalny.\
H1: Średni plon ziemniaków dla sposobu fc nie ma rozkładu normalnego.\
H0: Średni plon ziemniaków dla sposobu ff ma rozkład normalny.\
H1: Średni plon ziemniaków dla sposobu ff nie ma rozkładu normalnego.\
H0: Średni plon ziemniaków dla sposobu oo ma rozkład normalny.\
H1: Średni plon ziemniaków dla sposobu oo nie ma rozkładu normalnego.

```{r}
tapply(dane8$yield, dane8$virus, shapiro.test)
```

Dla każdej grupy na każdym sensownym poziomie isotności nie mamy podstaw do odrzucenia hipotezy zerowej, zatem dane w poszczególnych grupach pochodzą z populacji o rozkładzie normalnym.\

Test Levene’a dla jednorodności wariancji:\

H0: Wariancja plonu ziemniaków jest taka sama dla wszystkich sposobów zakażenia.\
H1: Wariancja plonu ziemniaków różni się w zależności od sposobu zakażenia.

```{r}
leveneTest(yield ~ virus, data = dane8)
```

P-wartość dla testu Levene’a jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem możemy przyjąć, że wariancja plonu ziemniaków jest taka sama dla wszystkich czterech sposobów zakażenia.\

Jako, wszystkie założenia zostały spełnione, możemy przeprowadzić test ANOVA:

H0: Średni plon ziemniaków jest taki sam dla wszystkich sposobów zakażenia.\
H1: Średni plon ziemniaków różni się od sposobu zakażenia.\

```{r}
model8A <- aov(yield ~ virus, data = dane8)
summary(model8A)
```

P-wartość dla testu ANOVA jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni plon ziemniaków różni się w zależności od sposobu zakażenia.

### (B)
analizy kontrastów sum. 

Model:\
$weight = \beta_0 + \beta_1*gFC + \beta_2*gFF + \beta_3*gOO$\

Kontrast 1:\
$0 > \beta_1 = \mu_{B} - \mu_{A}$\

H0: $\beta_1 = 0$\
H0: $\mu_{B} = \mu_{A}$\

Kontrast 2:\
$0 < \beta_2 = \mu_{C} - \mu_{A}$\

H0: $\beta_2 = 0$\
H0: $\mu_{C} = \mu_{A}$\

Kontrast 3:\
$0 < \beta_3 = \mu_{D} - \mu_{A}$\

H0: $\beta_3 = 0$\
H0: $\mu_{D} = \mu_{A}$\

```{r}
contrasts(dane8$virus) <- contr.sum
contrasts(dane8$virus)
S <- cbind(1, contrasts(dane8$virus))
S
S_2 <- solve(S)
library(MASS)
print("Macierz współczynników kontrastów:")
fractions(S_2)
```

Zdefiniowano kontrasty:\
$\beta_0 \quad to \quad L_1 = \frac{1}{4} (\mu_{A} + \mu_{B} + \mu_{C} + \mu_{D})$\
$\beta_1 \quad to \quad L_2 = \frac{3}{4} \mu_{A} - \frac{1}{4} (\mu_{B} + \mu_{C} + \mu_{D})$\
$\beta_2 \quad to \quad L_3 = -\frac{1}{4} \mu_{A} + \frac{3}{4} \mu_{B} - \frac{1}{4} (\mu_{C} + \mu_{D})$\
$\beta_3 \quad to \quad L_4 = -\frac{1}{4} (\mu_{A} + \mu_{B}) + \frac{3}{4} \mu_{C} - \frac{1}{4} \mu_{D}$\

H0: $L_k = 0$\
H1: $L_k \neq 0$\

```{r}
model8_contr <- lm(yield ~ virus, data = dane8, contrasts = contrasts(dane8$virus))
summary(model8_contr)
```

Dla kontrastu $L_2$ p-wartość jest większa niż przyjęty poziom istotności 0.05, więc nie mamy podstaw do odrzucenia hipotezy zerowej, zatem średni plon ziemniaka dla sposobu fc nie różni się istotnie od średniego plonu ziemniaka dla sposobu cc.\
Dla kontrastu $L_3$ p-wartość jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni plon ziemniaka dla sposobu ff istotnie różni się od średniego plonu ziemniaka dla sposobu cc i fc. Biorąc pod uwagę ujemny wpółczynnik (-14.76) możemy stwierdzić, że średni plon ziemniaka dla sposobu ff jest mniejszy niż dla sposobu cc i fc.\
Dla kontrastu $L_4$ p-wartość jest mniejsza niż przyjęty poziom istotności 0.05, więc odrzucamy hipotezę zerową, zatem średni plon ziemniaka dla sposobu oo istotnie różni się od średniego plonu ziemniaka dla sposobu cc, fc i ff. Biorąc pod uwagę dodatni wpółczynnik (8.71) możemy stwierdzić, że średni plon ziemniaka dla sposobu oo jest większy niż dla sposobu cc, fc i ff.\

## Zadanie 9.
Zbiór `datarium::titanic.raw` zawiera informacje o losach pasażerów podczas tragicznego pierwszego rejsu oceanicznego liniowca Titanic. W zbiorze znajdują się zmienne:\
`Class` - klasa podróży, `Sex` - płeć, `Age` - wiek, `Survived` - przeżycie pasażera.\

Przygotowanie danych:

```{r}
dane9 <- data.frame(titanic.raw)
head(dane9)
```

### (A)
Na podstawie zbioru `titanic.raw` zbuduj model określający szanse przeżycia pasażera Titanica i podaj interpretacje współczynników zbudowanego modelu.

```{r}
model9A <- glm(Survived ~ ., data = dane9, family = "binomial")
model9A
exp(coef(model9A))
```

Zbudowano model logistyczny wyjaśniający prawdopodobieństwo przeżycia pasażera Titanica (Survived) na podstawie wszystkich zmiennych, postaci Survived = 0.69 - 1.02 * Class2nd - 1.78 * Class3rd - 0.86 * ClassCrew + 2.42 * SexFemale - 1.06 * AgeAdult.\

 1. Podróż w klasie 2 względem 1 powoduje spadek szansy na przeżycie pasażera Titanica o około 64% przy założeniu stałości pozostałych zmiennych.\
 2. Podróż w klasie 3 względem 1 powoduje spadek szansy na przeżycie pasażera Titanica o około 83% przy założeniu stałości pozostałych zmiennych.\
 3. Podróż jak członek załogi względem podróży w klasie 1 powoduje spadek szansy na przeżycie pasażera Titanica o około 58% przy założeniu stałości pozostałych zmiennych.\
 4. Płeć żeńska w porównaniu do męskiej ma większe szanse na przeżycie o około 1025% przy założeniu stałości pozostałych zmiennych.\
 5. Bycie dorosłym w porównaniu do bycia dzieckiem powoduje spadek szansy na przeżycie pasażera Titanica o około 65% przy założeniu stałości pozostałych zmiennych.\

### (B)
Przyjmując próg klasyfikacyjny 0.4 stwórz zmienną zero-jedynkową `pred`, za pomocą której można określić, czy na podstawie zbudowanego modelu pasażer Titanica przeżył katastrofę, a następnie oblicz miary oceny jakości prognoz i na ich podstawie dokonaj oceny zbudowanego modelu.

```{r}
dane9$pred <- ifelse(predict(model9A, type = "response") >= 0.4, "Yes", "No")
head(dane9)
```

```{r}
confusionMatrix(as.factor(dane9$pred), as.factor(dane9$Survived), positive = "Yes")
```

  1. Na podstawie accuracy równego 0.76 wnioskujemy że model przewidział ok.76% poprawnych wartości.\
  2. Precision (pos pred value) wynosi 0.63 co oznacza że ze wszystkich przewidzianych pozytywnych przypadków ok.63% faktycznie było pozytywnych. Mówi się w takim przypadku, że model rzadko generuje fałszywe alarmy.\
  3. Czułość (sensitivity/recall) wynosi 0.59 co znaczy, że ok.59% osób, które przeżyły katastrofę model poprawnie wskazał.\ 
  4. Swoistość (specificity) wynosi 0.84 co znaczy, że ok.84% osób, które nie przeżyły katastrofy model wskazał poprawnie.\
  
Za pomocą zbudowanego modelu przyjmująć próg klasyfikacyjny 0.4 lepiej można przewidzieć to, że dane pasażer Titanica nie przeżył katastrofy niż to, że ją przeżył. Model ma wysoką precyzję i jest bardziej nastawiony na wykrywanie negatywnych przypadków.

## Zadanie 10.
Zbiór `caret::Sacramento` zawiera informacje o domach i cenach sprzedaży 932 nieruchomości w Sacramento, Kalifornia. W zbiorze znajdują się zmienne:\

  - city – miasto, w którym znajduje się nieruchomość,\
  - zip – kod pocztowy nieruchomości,\
  - beds – liczba sypialni w domu,\
  - baths – liczba łazienek w domu,\
  - sqft – powierzchnia domu w stopach kwadratowych,\
  - type – typ nieruchomości,\
  - price – cena sprzedaży nieruchomości w dolarach,\
  - latitude – szerokość geograficzna nieruchomości w stopniach,\
  - longitude – długość geograficzna nieruchomości w stopniach.\

Przygotowanie danych:

```{r}
data(Sacramento)
dane10 <- data.frame(Sacramento)
head(dane10)
```

### (A)
Na podstawie danych zawartych w zbiorze Sacramento zbuduj model, za pomocą którego można przewidzieć cenę domu na podstawie liczby sypialni (`beds`) i powierzchni (`sqft`). Zbadaj, czy w zbudowanym modelu istnieje interakcja między zmiennymi objaśniającymi.

```{r}
model10A <- lm(price ~ beds + sqft, data = dane10)
model10A
model10A_int <- lm(price ~ beds * sqft, data = dane10)
summary(model10A_int)
```

Zbudowano model liniowy wyjaśniający cenę domu (price) na podstawie liczby sypialni (beds) i powierzchni (sqft), postaci price = 60850.5 - 26035.1 * beds + 161.3 * sqft.\

P-wartość dla testu t jest mniejsza niż każdy sensownie przyjęty poziom istotności. W związku z tym odrzucamy hipotezę zerową, zatem nie mamy statystcznie istotną interakcję pomiędzy zmiennymi objaśniającymi.

### (B)
Zbadaj, czy w zbudowanym modelu (A) zostało naruszone założenie braku autokorelacji błędów. W przypadku odpowiedzi pozytywnej zlogarytmuj zmienną `sqft` i sprawdź, czy taka transformacja wymusiła brak autokorelacji błędów.

H0: Autokorelacja reszt I rzędu nie występuje\
H1: Autokorelacja reszt I rzędu występuje\

Test Durbin–Watsona:\

```{r}
dwtest(model10A, alternative = "two.sided")
```

P-wartość dla testu Durbin–Watsona jest mniejsza niż każdy sensownie przyjęty poziom istotności, więc odrzucamy hipotezę zerową, zatem w modelu występuje autokorelacja reszt I rzędu i założenie zostało naruszone.\

W związku z pojawieniem się autokorelacji I rzędu, nie ma potrzeby wykonywania testu Breuscha–Godfreya, w celu sprawdzenia autokorelacji reszt wyższych rzędów.\

Należy teraz zlogarytmować zmienną sqft i sprawdzić, czy taka transformacja wymusiła brak autokorelacji błędów.\

```{r}
model10B <- lm(price ~ beds + log(sqft), data = dane10)
model10B
```

Zbudowane nowy model liniowy wyjaśniający cenę domu (price) na podstawie liczby sypialni (beds) i logarytmu powierzchni (log(sqft)), postaci: price = -1907365 - 33589 * beds + 308202 * log(sqft).\

Przechodzimy do testy Durbin–Watsona w celu sprawdzenia autokrelacji reszt I rzędu:\

H0: Autokorelacja reszt I rzędu nie występuje\
H1: Autokorelacja reszt I rzędu występuje\

```{r}
dwtest(model10B, alternative = "two.sided")
```

P-wartość dla testu Durbin–Watsona jest mniejsza niż każdy sensownie przyjęty poziom istotności, więc odrzucamy hipotezę zerową, zatem w modelu z zlogarytmowaną zmienną sqft wciąż występuje korelacja reszt I rzędu. Wykonanie testu Breuscha–Godfreya nie jest wymagane.

### (C)
Podaj interpretacje współczynników modelu ze zlogarytmowaną zmienną `sqft`. 

```{r}
model10B
```

W modelu ze zlogarytmowaną zmienną sqft współczynniki interpretujemy następująco:\

 1. Współczynnik przy zmiennej beds (-33589) oznacza, że przy założeniu stałości pozostałych zmiennych, dodanie jednej sypialni do domu powoduje spadek ceny domu o około 33589 dolarów.\
 2. Współczynnik przy zmiennej log(sqft) (308202) oznacza, że przy założeniu stałości pozostałych zmiennych, wzrost logarytmu powierzchni domu o 1% powoduje wzrost ceny domu o około 3082,02 dolarów.

## Zadanie 11.
Rozważamy hipotetyczne dane dotyczące przyjęć na studia drugiego stopnia pewnego amerykańskiego uniwersytetu. Dane trzeba pobrać ze strony internetowej za pomocą kodu:\
  `dane <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")`\
W zbiorze znajdują się zmienne:\

  - admit – informuje, czy kandydat został przyjęty na studia (1 = tak, 0 = nie),\
  - gre – wynik testu GRE (Graduate Record Examination), standaryzowanego egzaminu używanego w USA przy rekrutacji na studia magisterskie,\
  - gpa – średnia ocen z ukończonych studiów pierwszego stopnia,\
  - rank – prestiż uniwersytetu, na który kandydat aplikuje (1–4), gdzie 1 = najbardziej prestiżowy, 4 = najmniej.\

Zmienne `gre` i `gpa` są ilościowe. Zmienną `rank` należy traktować jako jakościową, co można uczynić za pomocą polecenia:\

  `dane$rank <- factor(dane$rank)`\

Na podstawie tego zbioru chcemy ocenić szanse kandydata na dostanie się na studia drugiego stopnia.\

Przygotowanie danych:

```{r}
dane11 <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
dane11$rank <- factor(dane11$rank)
head(dane11)
```

### (A)
Zbuduj model, w którym zmienną objaśnianą jest zmienna`admit`, a zmiennymi objaśniającymi pozostałe zmienne.

```{r}
model11A <- glm(admit ~ ., data = dane11, family = "binomial")
model11A
```

Zbudowano model logistyczny wyjaśniający prawdopodobieństwo przyjęcia kandydata na studia (admit) na podstawie wszystkich zmiennych, postaci: admit = -3.99 + 0.002 * gre + 0.8 * gpa - 0.68 * rank2 - 1.34 * rank3 - 1.55 * rank4.

### (B)
Podaj interpretacje współczynników otrzymanego modelu.

```{r}
exp(coef(model11A))
```

 1. Wzrost wyniku testu GRE o 1 punkt powoduje wzrost szansy na przyjęcie kandydata na studia o około 0.2%, przy założeniu stałości pozostałych zmiennych.\
 2. Wzrost średniej ocen z ukończonych studiów pierwszego stopnia o 1 punkt powoduje wzrost szansy na przyjęcie kandydata na studia o około 123%, przy założeniu stałości pozostałych zmiennych.\
 3. Aplikowanie do uniwersytetu o rankingu 2 w porównaniu do aplikowania do uniwersytetu o rankingu 1 powoduje spadek szansy na przyjęcie kandydata na studia o około 49%, przy założeniu stałości pozostałych zmiennych.\
 4. Aplikowanie do uniwersytetu o rankingu 3 w porównaniu do aplikowania do uniwersytetu o rankingu 1 powoduje spadek szansy na przyjęcie kandydata na studia o około 74%, przy założeniu stałości pozostałych zmiennych.\
 5. Aplikowanie do uniwersytetu o rankingu 4 w porównaniu do aplikowania do uniwersytetu o rankingu 1 powoduje spadek szansy na przyjęcie kandydata na studia o około 79%, przy założeniu stałości pozostałych zmiennych.\

### (C)
Przyjmując próg klasyfikacyjny 0.5 stwórz zmienną zero-jedynkową `pred_admit`, za pomocą której można określić, czy na podstawie zbudowanego modelu kandydat dostanie się na studia, a następnie oblicz miary oceny jakości prognoz i na ich podstawie dokonaj oceny zbudowanego modelu. 

```{r}
dane11$pred_admit <- ifelse(predict(model11A, type = "response") >= 0.5, 1, 0)
head(dane11)
```

```{r}
confusionMatrix(as.factor(dane11$pred_admit), as.factor(dane11$admit), positive = "1")
```

  1. Na podstawie accuracy równego 0.71 wnioskujemy że model przewidział ok.71% poprawnych wartości.\
  2. Precision (pos pred value) wynosi 0.61 co oznacza że ze wszystkich przewidzianych pozytywnych przypadków ok.61% faktycznie było pozytywnych. Mówi się w takim przypadku, że model rzadko generuje fałszywe alarmy.\
  3. Czułość (sensitivity/recall) wynosi 0.24 co znaczy, że ok.24% osób, które zostały przyjęte na studia model poprawnie wskazał.\ 
  4. Swoistość (specificity) wynosi 0.93 co znaczy, że ok.93% osób, które nie zostały przyjęte na studia model wskazał poprawnie.\

Za pomocą zbudowanego modelu przyjmująć próg klasyfikacyjny 0.5 lepiej można przewidzieć to, że u badani kandydaci na studia nie zostaną przyjęci, niż to, że zostaną. Model jest bardziej nastawiony na wykrywanie negatywnych przypadków.
